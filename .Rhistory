dev.off()
#########################################
## Train xgboost RF model
#########################################
current_name <- "_rf"
set.seed(20160522)
test_set <- sort(sample(nrow(d), 400))
train_set <- seq(1,nrow(d))[-test_set]
task <- makeRegrTask(
id = "pisa",
data = as.data.frame(d[, c(demographics, dispositions, maths_literacy[1]), with = F]),
target = paste0("PV", 1, "MATH")
)
lrn_rf <- makeLearner(
"regr.xgboost",
par.vals = list(
nrounds = 1,
print.every.n = 800,
subsample = 0.5,
max_depth = 20,
num_parallel_tree = 2000,
colsample_bytree = 0.15
)
)
parallelStartSocket(8)
fit_rf <- train(lrn_rf, task = task, subset = train_set)
parallelStop()
pred_rf <- as.data.table(predict(fit_rf, task = task, subset = test_set))
### RF outputs
trplot_rf <- ggplot(pred_rf, aes(truth, response)) +
geom_point() +
geom_abline(colour = "red", linetype = "dashed")
error_table[, RF := pred_rf[, quantile(abs(truth-response), c(.5, .9, .99))] ]
imp_rf <- xgb.importance(feature_names = fit_rf$features, model = fit_rf$learner.model)
write.table(imp_rf, paste0("Outputs/Tables/feature_importance", current_name, ".csv"), row.names = F, col.names = T, sep = ",")
impplot_rf <- xgb.plot.importance(imp_rf)
#xgb.plot.multi.trees(fit_rf$learner.model, feature_names = fit_rf$features)
pd_rf <- generatePartialPredictionData(fit_rf, task, imp_rf$Feature)
write.table(pd_rf$data, paste0("Outputs/Tables/partial_dependency", current_name, ".csv"), row.names = F, col.names = T, sep = ",")
pdplot_rf <- plotPartialPrediction(pd_rf)
pdf(file = paste0("Outputs/Plots/trplot", current_name, ".pdf"),
width = 8, height = 8)
print(trplot_rf)
dev.off()
pdf(paste0("Outputs/Plots/impplot", current_name, ".pdf"),
width = 8, height = 8)
impplot_rf
dev.off()
pdf(paste0("Outputs/Plots/pdplot", current_name, ".pdf"),
width = 12, height = 8)
pdplot_rf
dev.off()
####
write.table(error_table, "Outputs/Tables/error_table.csv", row.names = F, col.names = T, sep = ",")
#########################################
## Train xgboost RF model
#########################################
current_name <- "_rf"
set.seed(20160522)
test_set <- sort(sample(nrow(d), 400))
train_set <- seq(1,nrow(d))[-test_set]
task <- makeRegrTask(
id = "pisa",
data = as.data.frame(d[, c(demographics, dispositions, maths_literacy[1]), with = F]),
target = paste0("PV", 1, "MATH")
)
lrn_rf <- makeLearner(
"regr.xgboost",
par.vals = list(
nrounds = 1,
print.every.n = 800,
subsample = 0.5,
max_depth = 20,
num_parallel_tree = 8000,
colsample_bytree = 0.15
)
)
parallelStartSocket(8)
fit_rf <- train(lrn_rf, task = task, subset = train_set)
parallelStop()
pred_rf <- as.data.table(predict(fit_rf, task = task, subset = test_set))
### RF outputs
trplot_rf <- ggplot(pred_rf, aes(truth, response)) +
geom_point() +
geom_abline(colour = "red", linetype = "dashed")
error_table[, RF := pred_rf[, quantile(abs(truth-response), c(.5, .9, .99))] ]
imp_rf <- xgb.importance(feature_names = fit_rf$features, model = fit_rf$learner.model)
write.table(imp_rf, paste0("Outputs/Tables/feature_importance", current_name, ".csv"), row.names = F, col.names = T, sep = ",")
impplot_rf <- xgb.plot.importance(imp_rf)
#xgb.plot.multi.trees(fit_rf$learner.model, feature_names = fit_rf$features)
pd_rf <- generatePartialPredictionData(fit_rf, task, imp_rf$Feature)
write.table(pd_rf$data, paste0("Outputs/Tables/partial_dependency", current_name, ".csv"), row.names = F, col.names = T, sep = ",")
pdplot_rf <- plotPartialPrediction(pd_rf)
pdf(file = paste0("Outputs/Plots/trplot", current_name, ".pdf"),
width = 8, height = 8)
print(trplot_rf)
dev.off()
pdf(paste0("Outputs/Plots/impplot", current_name, ".pdf"),
width = 8, height = 8)
impplot_rf
dev.off()
pdf(paste0("Outputs/Plots/pdplot", current_name, ".pdf"),
width = 12, height = 8)
pdplot_rf
dev.off()
####
write.table(error_table, "Outputs/Tables/error_table.csv", row.names = F, col.names = T, sep = ",")
?as.IDate
?month
?dayofyear
?day
?yearday
?dayyear
?year
?gbm.interaction
library(gbm)
install.packages("gbm")
library(gbm)
?gbm.interaction
?gbm.interactions
intall.packages("dismo")
install.packages("dismo")
install.packages("dismo")
install.packages("~/Downloads/dismo_1.1-1.tgz", repos = NULL, type = .Platform$pkgType)
library(dismo)
?gbm.interactions
?gbm
fimp_tree <- fread("Outputs/Tables/feature_importance_tree.csv")
fimp_stump <- fread("Outputs/Tables/feature_importance_stump.csv")
fimp_tree
setkey(fimp_tree, "Feature")
setkey(fimp_stump, "Feature")
setnames(fimp_tree, "Gain", "Gain_tree")
setnames(fimp_stump, "Gain", "Gain_stump")
fimp_stump[, .(Feature, Gain_stump)][fimp_tree[, .(Feature, Gain_tree)]]
fimp <- fimp_stump[, .(Feature, Gain_stump)][fimp_tree[, .(Feature, Gain_tree)]]
ggplot(fimp, aes(reorder(Feature, Gain_tree))) +
geom_bar(stat = "identity", aes(y = Gain_stump)) +
geom_bar(stat = "identity", aes(y = Gain_tree), colour = "red")
geom_bar(stat = "identity", aes(y = Gain_tree), fill = "red")
ggplot(fimp, aes(reorder(Feature, Gain_tree))) +
geom_bar(stat = "identity", aes(y = Gain_stump)) +
geom_bar(stat = "identity", aes(y = Gain_tree), fill = "red")
geom_bar(stat = "identity", aes(y = Gain_tree), fill = "red", alpha = 0.3)
ggplot(fimp, aes(reorder(Feature, Gain_tree))) +
geom_bar(stat = "identity", aes(y = Gain_stump)) +
geom_bar(stat = "identity", aes(y = Gain_tree), fill = "red", alpha = 0.3)
ggplot(fimp, aes(reorder(Feature, Gain_tree), Gain_tree - Gain_stump)) + geom_bar(stat = "identity")
ggplot(fimp, aes(reorder(Feature, Gain_tree), Gain_tree - Gain_stump)) + geom_bar(stat = "identity") + coord_flip()
fimp <- fimp_stump[, .(Feature, Gain_tree - Gain_stump)][fimp_tree[, .(Feature, Gain_tree)]]
ggplot(fimp, aes(reorder(Feature, Gain_tree - Gain_stump), Gain_tree - Gain_stump)) + geom_bar(stat = "identity") + coord_flip()
source('~/Projects/pisa-dispositions/Scripts/2_tuning_and_cv_GBM.R', echo=TRUE)
opt
g <- ggplot(opt, aes(
x = reorder(interaction.depth, as.numeric(as.character(interaction.depth))),
y = mae.test.mean,
group = as.numeric(as.character(shrinkage)),
colour = reorder(shrinkage, as.numeric(as.character(shrinkage)))
))
g + geom_line() + geom_point()
2^14
2^14 *.005
?gbm
?generatePartialPredictionData
imp_tree
source('~/Projects/pisa-dispositions/Scripts/6_train_gbm.R', echo=TRUE)
imp_gbm <- summary(fit_gbm$learner.model)
imp_gbm
ggplot(imp_gbm, aes(var, rel.inf)) +
geom_bar(stat = "identity") +
coord_flip()
ggplot(imp_gbm, aes(reorder(var, rel.inf), rel.inf)) +
geom_bar(stat = "identity") +
coord_flip()
int_gbm <- gbm.interactions(fit_gbm$learner.model)
?gbm.interactions
mode(fit_gbm$learner.model)
is.gbm(fit_gbm$learner.model)
fit_gbm$learner.model
error_table
quantile(abs(truth-response), c(.5, .9, .99))
pred_gbm
pred_gbm[, quantile(abs(truth-response), c(.5, .9, .99))]
trplot_gbm
error_table[, GBM := pred_gbm[, quantile(abs(truth-response), c(.5, .9, .99))] ]
error_table
int_gbm <- gbm.interactions(fit_gbm$learner.model)
int_gbm <- gbm.interactions(fit_gbm)
fit_gbm
fit_gbm$learner.model
model_gbm <-
gbm(PV1MATH ~ .,
data = as.data.frame(d[, c(demographics, dispositions, maths_literacy[1]), with = F]),
n.trees = 3000,
shrinkage = 0.01,
interaction.depth = 4,
bag.fraction = 0.5,
)
model_gbm <-
gbm(PV1MATH ~ .,
data = as.data.frame(d[, c(demographics, dispositions, maths_literacy[1]), with = F]),
n.trees = 3000,
shrinkage = 0.01,
interaction.depth = 4,
bag.fraction = 0.5,
verbose = T
)
model_gbm <-
gbm(PV1MATH ~ .,
data = as.data.frame(d[, c(demographics, dispositions, maths_literacy[1]), with = F]),
n.trees = 3000,
shrinkage = 0.001,
interaction.depth = 4,
bag.fraction = 0.5,
verbose = T
)
summary(model_gbm)
int_gbm <- gbm.interactions(model_gbm)
?gbm.step
c(demographics, dispositions)
demographics <- c("GENDER", "ESCS", "STATE", "GEOLOC", "INDIG")
c(demographics, dispositions)
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
max.trees = 3000,
learning.rate = 0.01,
interaction.depth = 4,
bag.fraction = 0.5,
verbose = T
)
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
n.trees = 1000,
max.trees = 3000,
learning.rate = 0.01,
interaction.depth = 4,
bag.fraction = 0.5,
verbose = T
)
summary(model_gbm)
int_gbm <- gbm.interactions(model_gbm)
int_gbm$rank.list
int_gbm$interactions
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
n.trees = 1000,
max.trees = 3000,
learning.rate = 0.01,
tree.complexity = 4,
bag.fraction = 0.5,
verbose = T
)
summary(model_gbm)
int_gbm <- gbm.interactions(model_gbm)
int_gbm$rank.list
write.table(int_gbm$rank.list, "Outputs/Tables/interaction_ranks.csv", row.names = F, col.names = T, sep = ",")
write.table(int_gbm$interactions, "Outputs/Tables/interaction_full_table.csv", row.names = F, col.names = T, sep = ",")
int_gbm$interactions
int_gbm$rank.list
gbm.perspec(model_gbm, 5, 4, y.range=c(15,20), z.range=c(0,0.6))
?gbm.perspec
gbm.perspec(model_gbm, 5, 4)
gbm.perspec(model_gbm, 43, 34)
gbm.perspec(model_gbm, 21, 2)
d[, quantile(ESCS)]
gbm.perspec(model_gbm, 21, 2, z.range = c(0, 1000), y.range = c(-3.81, 2.44), x.range = c(1,4))
d[, quantile(PV1MATH)]
gbm.perspec(model_gbm, 21, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
d[, unique(INDIG)]
gbm.perspec(model_gbm, 52, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
as.numeric(d[, unique(INDIG)])
as.numeric(d[, unique(GEOLOC)])
d[, unique(GEOLOC)]
for(col in demographics) {
if(is.factor(d[[col]])) {
set(d, j = col, value = as.numeric(d[[col]]))
}
}
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
n.trees = 1000,
max.trees = 3000,
learning.rate = 0.01,
tree.complexity = 4,
bag.fraction = 0.5,
verbose = T
)
int_gbm <- gbm.interactions(model_gbm)
int_gbm$rank.list
d <- fread("Data/Clean/imputed_aus_data.csv")
#########################################
## Columns
#########################################
identifiers <- c("STRATUM", "SCHOOLID", "StIDStd", "BIRTHMONTH", "BIRTHYEAR")
demographics <- c("GENDER", "ESCS", "STATE", "GEOLOC", "INDIG")
int_motivation <- c("ST29Q01", "ST29Q03", "ST29Q04", "ST29Q06") # intrinsic motivation INTMAT
ext_motivation <- c("ST29Q02", "ST29Q05", "ST29Q07", "ST29Q08") # extrinsic motivation INSTMOT
self_concept <- c("ST42Q02", "ST42Q04", "ST42Q06", "ST42Q07", "ST42Q09") # SCMAT
self_efficacy <- c("ST37Q01", "ST37Q02", "ST37Q03", "ST37Q04", "ST37Q05", "ST37Q06", "ST37Q07", "ST37Q08") # MATHEFF
control_in_school <- c("ST91Q01", "ST91Q02", "ST91Q03", "ST91Q04", "ST91Q05", "ST91Q06")
control_in_maths <- c("ST43Q01", "ST43Q02", "ST43Q03", "ST43Q04", "ST43Q05", "ST43Q06")
attr_failure <- c("ST44Q01", "ST44Q03", "ST44Q04", "ST44Q05", "ST44Q07", "ST44Q08") # FAILMAT
maths_anxiety <- c("ST42Q01", "ST42Q03", "ST42Q05", "ST42Q08", "ST42Q10") # ANXMAT
subj_norms <- c("ST35Q01", "ST35Q02", "ST35Q03", "ST35Q04", "ST35Q05", "ST35Q06") # SUBNORM
dispositions <- c(int_motivation, ext_motivation, self_concept,
self_efficacy, control_in_school, control_in_maths, attr_failure,
maths_anxiety, subj_norms)
maths_literacy <- paste0("PV", 1:5, "MATH")
maths_literacy_level <- paste0("PV", 1:5, "MATH_LEVEL")
#########################################
## Make demographics columns into factors
#########################################
for (col in c("GENDER", "STATE", "GEOLOC", "INDIG"))
set(d, j=col, value=as.factor(d[[col]]))
#########################################
## Restrict imputed item responses to within 1:4
#########################################
for(col in dispositions) {
set(d, i = which(d[[col]] < 1), j = col, value = 1)
set(d, i = which(d[[col]] > 4), j = col, value = 4)
}
for(col in c("INDIG", "GENDER")) {
if(is.factor(d[[col]])) {
set(d, j = col, value = as.numeric(d[[col]]))
}
}
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
n.trees = 1000,
max.trees = 3000,
learning.rate = 0.01,
tree.complexity = 4,
bag.fraction = 0.5,
verbose = T
)
int_gbm <- gbm.interactions(model_gbm)
#write.table(int_gbm$rank.list, "Outputs/Tables/interaction_ranks.csv", row.names = F, col.names = T, sep = ",")
#write.table(int_gbm$interactions, "Outputs/Tables/interaction_full_table.csv", row.names = F, col.names = T, sep = ",")
int_gbm$rank.list
gbm.perspec(model_gbm, 21, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
gbm.perspec(model_gbm, 5, 4, z.range = c(425, 560), y.range = c(1,8), x.range = c(1,2))
gbm.perspec(model_gbm, 5, 3, z.range = c(425, 560), y.range = c(1,8), x.range = c(1,2))
gbm.perspec(model_gbm, 3, 5, z.range = c(425, 560), y.range = c(1,8), x.range = c(1,2))
gbm.perspec(model_gbm, 3, 5, z.range = c(425, 560), y.range = c(1,2), x.range = c(1,2))
int_gbm$rank.list
int_gbm$rank.list %>% head
library(magrittr)
int_gbm$rank.list %>% head
gbm.perspec(model_gbm, 4, 5, z.range = c(425, 560), y.range = c(1,2), x.range = c(1,3))
gbm.perspec(model_gbm, 21, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
gbm.perspec(model_gbm, 23, 20, z.range = c(425, 560), y.range = c(1,4), x.range = c(1,4))
gbm.perspec(model_gbm, 20, 23, z.range = c(425, 560), y.range = c(1,4), x.range = c(1,4))
gbm.perspec(model_gbm, 23, 20, z.range = c(425, 560), y.range = c(1,4), x.range = c(1,4))
gbm.perspec(model_gbm, 31, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
gbm.plot(model_gbm, n.plots = 5)
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
n.trees = 1000,
max.trees = 3000,
learning.rate = 0.001,
tree.complexity = 4,
bag.fraction = 0.5,
verbose = T
)
gbm.plot(model_gbm, n.plots = 12)
int_gbm <- gbm.interactions(model_gbm)
#write.table(int_gbm$rank.list, "Outputs/Tables/interaction_ranks.csv", row.names = F, col.names = T, sep = ",")
#write.table(int_gbm$interactions, "Outputs/Tables/interaction_full_table.csv", row.names = F, col.names = T, sep = ",")
int_gbm$rank.list %>% head
gbm.plot.fits(model_gbm, n.plots = 12)
gbm.plot.fits(model_gbm)
gbm.plot(model_gbm, n.plots = 12)
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
n.trees = 300,
max.trees = 3000,
learning.rate = 0.01,
tree.complexity = 4,
bag.fraction = 0.5,
verbose = T
)
gbm.plot(model_gbm, n.plots = 12)
int_gbm <- gbm.interactions(model_gbm)
#write.table(int_gbm$rank.list, "Outputs/Tables/interaction_ranks.csv", row.names = F, col.names = T, sep = ",")
#write.table(int_gbm$interactions, "Outputs/Tables/interaction_full_table.csv", row.names = F, col.names = T, sep = ",")
int_gbm$rank.list %>% head
model_gbm <-
gbm.step(gbm.y = "PV1MATH",
gbm.x = c(demographics, dispositions),
data = as.data.frame(d),
family = "gaussian",
n.folds = 5,
n.trees = 2000,
max.trees = 3000,
learning.rate = 0.01,
tree.complexity = 4,
bag.fraction = 0.5,
verbose = T
)
gbm.plot(model_gbm, n.plots = 12)
int_gbm <- gbm.interactions(model_gbm)
#write.table(int_gbm$rank.list, "Outputs/Tables/interaction_ranks.csv", row.names = F, col.names = T, sep = ",")
#write.table(int_gbm$interactions, "Outputs/Tables/interaction_full_table.csv", row.names = F, col.names = T, sep = ",")
int_gbm$rank.list %>% head
gbm.perspec(model_gbm, 23, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
?persp
gbm.perspec(model_gbm, 23, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4), col = rainbow(6))
gbm.perspec(model_gbm, 23, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
int_gbm$rank.list %>% head
int_gbm$rank.list
gbm.perspec(model_gbm, 3, 5, z.range = c(425, 560), y.range = c(1,2), x.range = c(1,2))
gbm.perspec(model_gbm, 3, 5, z.range = c(350, 560), y.range = c(1,2), x.range = c(1,2))
model_gbm
gbm.perspec(model_gbm, 7, 3, z.range = c(425, 560), y.range = c(1,8), x.range = c(1,4))
gbm.perspec(model_gbm, 23, 2, z.range = c(425, 560), y.range = c(-3.81, 2.44), x.range = c(1,4))
gbm.perspec(model_gbm, 23, 2, z.range = c(425, 580), y.range = c(-3.81, 2.44), x.range = c(1,4))
int_gbm$rank.list %>% head
gbm.perspec(model_gbm, 4, 5, z.range = c(425, 560), y.range = c(1,2), x.range = c(1,3))
int_gbm$rank.list
gbm.perspec(model_gbm, 23, 20, z.range = c(425, 560), y.range = c(1,4), x.range = c(1,4))
sqrt(2632)
?xgboost
log2(14481)
sqrt(56)
error_table <- data.table(percentile = c("pc50", "pc90", "pc99"),
Trees = c(0,0,0),
Stumps = c(0,0,0),
RF = c(0,0,0))
error_table[, Trees := pred_tree[, quantile(abs(truth-response), c(.5, .9, .99))] ]
error_table[, Stumps := pred_stump[, quantile(abs(truth-response), c(.5, .9, .99))] ]
current_name <- "_rf"
set.seed(20160522)
test_set <- sort(sample(nrow(d), 400))
train_set <- seq(1,nrow(d))[-test_set]
task <- makeRegrTask(
id = "pisa",
data = as.data.frame(d[, c(demographics, dispositions, maths_literacy[1]), with = F]),
target = paste0("PV", 1, "MATH")
)
lrn_rf <- makeLearner(
"regr.xgboost",
par.vals = list(
nrounds = 1,
print.every.n = 800,
subsample = 0.5,
max_depth = 20,
num_parallel_tree = 2000,
colsample_bylevel = 0.15
)
)
parallelStartSocket(8)
fit_rf <- train(lrn_rf, task = task, subset = train_set)
parallelStop()
pred_rf <- as.data.table(predict(fit_rf, task = task, subset = test_set))
### RF outputs
trplot_rf <- ggplot(pred_rf, aes(truth, response)) +
geom_point() +
geom_abline(colour = "red", linetype = "dashed")
error_table[, RF := pred_rf[, quantile(abs(truth-response), c(.5, .9, .99))] ]
imp_rf <- xgb.importance(feature_names = fit_rf$features, model = fit_rf$learner.model)
write.table(imp_rf, paste0("Outputs/Tables/feature_importance", current_name, ".csv"), row.names = F, col.names = T, sep = ",")
impplot_rf <- xgb.plot.importance(imp_rf)
#xgb.plot.multi.trees(fit_rf$learner.model, feature_names = fit_rf$features)
pd_rf <- generatePartialPredictionData(fit_rf, task, imp_rf$Feature)
write.table(pd_rf$data, paste0("Outputs/Tables/partial_dependency", current_name, ".csv"), row.names = F, col.names = T, sep = ",")
pdplot_rf <- plotPartialPrediction(pd_rf)
pdf(file = paste0("Outputs/Plots/trplot", current_name, ".pdf"),
width = 8, height = 8)
print(trplot_rf)
dev.off()
pdf(paste0("Outputs/Plots/impplot", current_name, ".pdf"),
width = 8, height = 8)
impplot_rf
dev.off()
pdf(paste0("Outputs/Plots/pdplot", current_name, ".pdf"),
width = 12, height = 8)
pdplot_rf
dev.off()
####
write.table(error_table, "Outputs/Tables/error_table.csv", row.names = F, col.names = T, sep = ",")
error_table
trplot_rf
imp$Feature
imp

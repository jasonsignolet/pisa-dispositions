results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y_5foldCV[[1]][[fold]],
MISSING = is.na(Y_5foldCV[[1]][[fold]]),
nq = nq, ns = ns, nf = nf, lambda = 1, #alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000))
View(col_filt_cv5f)
source('~/.active-rstudio-document', echo=TRUE)
J_counter
J_counter[, .(nf, Jtrain / (sum(!MISSING) * 0.8), Jtest / (sum(!MISSING) * 0.2))]
J_counter = as.data.table(J_counter)
J_counter[, .(nf, Jtrain / (sum(!MISSING) * 0.8), Jtest / (sum(!MISSING) * 0.2))]
J_summary <- J_counter[, .(nf, Jtrain / (sum(!MISSING) * 0.8), Jtest / (sum(!MISSING) * 0.2)), by = nf]
J_summary
J_counter[, .(nf, Jtrain / (sum(!MISSING) * 0.8), Jtest / (sum(!MISSING) * 0.2)), by = nf]
J_summary <- J_counter[, .(Jtrain / (sum(!MISSING) * 0.8), Jtest / (sum(!MISSING) * 0.2)), by = nf]
J_summary
J_counter[, .(mean(Jtrain / (sum(!MISSING) * 0.8)), mean(Jtest / (sum(!MISSING) * 0.2))), by = nf]
registerDoParallel()
J_counter <-
foreach(nf = 1:3, .combine = rbind) %:%
foreach(fold = 1:5, .combine = rbind) %dopar%{
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y_5foldCV[[1]][[fold]],
MISSING = is.na(Y_5foldCV[[1]][[fold]]),
nq = nq, ns = ns, nf = nf, lambda = 1, alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000))
test_error <- cost(results$par, Y_5foldCV[[2]][[fold]], MISSING = is.na(Y_5foldCV[[2]][[fold]]),
nq, ns, nf, lambda)
output <- data.frame(nf = nf, fold = fold, Jtrain = results$value, Jtest = test_error)
}
J_counter <-
foreach(nf = 1:3, .combine = rbind) %:%
foreach(fold = 1:5, .combine = rbind) %dopar%{
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y_5foldCV[[1]][[fold]],
MISSING = is.na(Y_5foldCV[[1]][[fold]]),
nq = nq, ns = ns, nf = nf, lambda = 1#, alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000))
test_error <- cost(results$par, Y_5foldCV[[2]][[fold]], MISSING = is.na(Y_5foldCV[[2]][[fold]]),
nq, ns, nf, lambda)
output <- data.frame(nf = nf, fold = fold, Jtrain = results$value, Jtest = test_error)
}
J_counter <-
foreach(nf = 1:3, .combine = rbind) %:%
foreach(fold = 1:5, .combine = rbind) %dopar%{
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y_5foldCV[[1]][[fold]],
MISSING = is.na(Y_5foldCV[[1]][[fold]]),
nq = nq, ns = ns, nf = nf, lambda = 1, #alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000))
test_error <- cost(results$par, Y_5foldCV[[2]][[fold]], MISSING = is.na(Y_5foldCV[[2]][[fold]]),
nq, ns, nf, lambda)
output <- data.frame(nf = nf, fold = fold, Jtrain = results$value, Jtest = test_error)
}
J_counter[, .(mean(Jtrain / (sum(!MISSING) * 0.8)), mean(Jtest / (sum(!MISSING) * 0.2))), by = nf]
J_counter
registerDoParallel()
J_counter <-
foreach(nf = 1:3, .combine = rbind) %:%
foreach(fold = 1:5, .combine = rbind) %dopar%{
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y_5foldCV[[1]][[fold]],
MISSING = is.na(Y_5foldCV[[1]][[fold]]),
nq = nq, ns = ns, nf = nf, lambda = 1, #alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000))
test_error <- cost(results$par, Y_5foldCV[[2]][[fold]], MISSING = is.na(Y_5foldCV[[2]][[fold]]),
nq, ns, nf, lambda)
output <- data.table(nf = nf, fold = fold, Jtrain = results$value, Jtest = test_error)
}
registerDoParallel()
J_counter <-
foreach(nf = 1:3, .combine = rbind) %:%
foreach(fold = 1:5, .combine = rbind, .multicombine = T, .packages = "data.table") %dopar%{
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y_5foldCV[[1]][[fold]],
MISSING = is.na(Y_5foldCV[[1]][[fold]]),
nq = nq, ns = ns, nf = nf, lambda = 1, #alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000))
test_error <- cost(results$par, Y_5foldCV[[2]][[fold]], MISSING = is.na(Y_5foldCV[[2]][[fold]]),
nq, ns, nf, lambda)
output <- data.table(nf = nf, fold = fold, Jtrain = results$value, Jtest = test_error)
}
J_counter[, .(mean(Jtrain / (sum(!MISSING) * 0.8)), mean(Jtest / (sum(!MISSING) * 0.2))), by = nf]
J_counter <-
foreach(nf = 1:7, .combine = rbind) %:%
foreach(fold = 1:5, .combine = rbind, .multicombine = T, .packages = "data.table") %dopar%{
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y_5foldCV[[1]][[fold]],
MISSING = is.na(Y_5foldCV[[1]][[fold]]),
nq = nq, ns = ns, nf = nf, lambda = 1, #alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000))
test_error <- cost(results$par, Y_5foldCV[[2]][[fold]], MISSING = is.na(Y_5foldCV[[2]][[fold]]),
nq, ns, nf, lambda)
output <- data.table(nf = nf, fold = fold, Jtrain = results$value, Jtest = test_error)
}
registerDoSEQ()
J_counter[, .(mean(Jtrain / (sum(!MISSING) * 0.8)), mean(Jtest / (sum(!MISSING) * 0.2))), by = nf]
J_summary <-
J_counter[, .(
mean(Jtrain / (sum(!MISSING) * 0.8)),
mean(Jtest / (sum(!MISSING) * 0.2))
), by = nf]
ggplot(J_summary, aes(nf)) + geom_line(aes(y = V1), colour = "red") + geom_line(aes(y = V2), colour = "blue")
source("Scripts/1_ETL_col_filt_tune.R")
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/1_ETL_col_filt_tune.R', echo=TRUE)
J_summary
ggplot(J_summary, aes(nf)) + geom_line(aes(y = V1), colour = "red") + geom_line(aes(y = V2), colour = "blue")
ggplot(J_summary, aes(nf)) + geom_line(aes(y = V1), colour = "red") + geom_line(aes(y = V2), colour = "blue")
ggplot(J_summary, aes(nf)) + geom_line(aes(y = V1), colour = "red")
dev.off()
ggplot(J_summary, aes(nf)) + geom_line(aes(y = V1), colour = "red") + geom_line(aes(y = V2), colour = "blue")
ggplot(J_summary, aes(nf)) +
geom_line(aes(y = V1), colour = "red") +
geom_line(aes(y = V3), colour = "blue") +
geom_errorbar(aes(ymin = V1 - V2/2, ymax = V1 + v2/2)) +
geom_errorbar(aes(ymin = V3 - V4/2, ymax = V3 + v4/2))
J_summary
ggplot(J_summary, aes(nf)) +
geom_line(aes(y = V1), colour = "red") +
geom_line(aes(y = V3), colour = "blue")
ggplot(J_summary, aes(nf)) +
geom_line(aes(y = V1), colour = "red") +
geom_line(aes(y = V3), colour = "blue") +
geom_errorbar(aes(ymin = V1 - V2/2, ymax = V1 + v2/2))
ggplot(J_summary, aes(nf)) +
geom_line(aes(y = V1), colour = "red") +
geom_line(aes(y = V3), colour = "blue") +
geom_errorbar(aes(ymin = V1 - V2 /2, ymax = V1 + v2 /2)) +
geom_errorbar(aes(ymin = V3 - V4 /2, ymax = V3 + v4 /2))
ggplot(J_summary, aes(nf)) +
geom_line(aes(y = V1), colour = "red") +
geom_line(aes(y = V3), colour = "blue") +
geom_errorbar(aes(ymin = V1 - V2 /2, ymax = V1 + V2 /2)) +
geom_errorbar(aes(ymin = V3 - V4 /2, ymax = V3 + v4 /2))
ggplot(J_summary, aes(nf)) +
geom_line(aes(y = V1), colour = "red") +
geom_line(aes(y = V3), colour = "blue") +
geom_errorbar(aes(ymin = V1 - V2 /2, ymax = V1 + V2 /2)) +
geom_errorbar(aes(ymin = V3 - V4 /2, ymax = V3 + V4 /2))
nf <- 6
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y, MISSING = MISSING, nq = nq, ns = ns, nf = 4, lambda = 1, alpha = 0.001,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000)
)
output <- vec2matrix(results$par, Y, MISSING, nq, ns, nf = 4)
X <- output[[1]]
THETA <- output[[2]]
GUESS <- round(THETA %*% t(X))
Y[MISSING] <- GUESS[MISSING]
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y, MISSING = MISSING, nq = nq, ns = ns, nf = 4, lambda = 1,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000)
)
dim(Y)
dim(MISSING)
nq
ns
nf
nf <- 6
results <- optim(par = runif(nq*nf + ns*nf, -1, 1),
fn = cost,
gr = gradient,
Y = Y,
MISSING = MISSING,
nq = nq,
ns = ns,
nf = nf,
lambda = 1,
method = "L-BFGS-B",
control = list(trace = 1,
maxit = 1000)
)
output <- vec2matrix(results$par, Y, MISSING, nq, ns, nf = 4)
results$par
dim(results$par)
length(results$par)
output <- vec2matrix(results$par, Y, MISSING, nq, ns, nf)
X <- output[[1]]
THETA <- output[[2]]
GUESS <- round(THETA %*% t(X))
Y[MISSING] <- GUESS[MISSING]
Y = Y + 2.5
head(Y)
dim(Y)
stu[, c(identifiers, demographics, maths_literacy), with = F]
stu
stu[, names(stu) %in% dispositions, with = F]
stu[, !names(stu) %in% dispositions, with = F]
cbind(stu[, !names(stu) %in% dispositions, with = F], Y)
imputed_table <- cbind(stu[, !names(stu) %in% dispositions, with = F], Y)
write.table(imputed_table, "Data/Clean/imputed_aus_data.csv", col.names = T, rrow.names = F, sep = ",")
write.table(imputed_table, "Data/Clean/imputed_aus_data.csv", col.names = T, row.names = F, sep = ",")
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/1_ETL.R', echo=TRUE)
pdf(file = "Outputs/Plots/tune_nf_to_impute_missing_values.pdf", width = 8, height = 8)
print(p1)
dev.off()
p1 <-  ggplot(J_summary, aes(nf)) +
geom_line(aes(y = V1), colour = "red") +
geom_line(aes(y = V3), colour = "blue") +
geom_errorbar(aes(ymin = V1 - V2 /2, ymax = V1 + V2 /2)) +
geom_errorbar(aes(ymin = V3 - V4 /2, ymax = V3 + V4 /2))
pdf(file = "Outputs/Plots/tune_nf_to_impute_missing_values.pdf", width = 8, height = 8)
print(p1)
dev.off()
sqrt(.22)
install.packages(c("mlr", "xgboost"))
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/1_ETL.R', echo=TRUE)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/0_functions.R', echo=TRUE)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/1_ETL.R', echo=TRUE)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/1_ETL.R', echo=TRUE)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/1_ETL.R', echo=TRUE)
p1
sum(MISSING)
sum(!MISSING)
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("xgboost", repos="http://dmlc.ml/drat/", type = "source")
install.packages("RTools")
source('~/.active-rstudio-document', echo=TRUE)
install.packages("mlr")
library("devtools")
install.packages("devtools")
install.packages("mlr")
install.packages("mlr")
devtools::install_github("mlr-org/mlr")
install.library("xgboost")
install.packages("xgboost")
source('~/.active-rstudio-document', echo=TRUE)
d <- fread("Data/Clean/imputed_aus_data.csv")
names(d)
?xgboost
10^(-4:0)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
demographics
for (col in c("GENDER", "STATE", "GEOLOC", "INDIG"))
set(d, j=col, value=as.factor(dt[[col]]))
col
for (col in c("GENDER", "STATE", "GEOLOC", "INDIG"))
set(d, j=col, value=as.factor(d[[col]]))
str(d)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
lrn$par.set
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
lrn <- makeLearner(
"regr.xgboost",
par.vals = list(
nrounds = 2000,
print.every.n = 200,
early.stop.round = 5,
maximize = FALSE,
subsample = 0.5
)
)
lrn$par.vals
ps <- makeParamSet(
makeDiscreteParam("eta", values = 10^(-4:0)),
makeDiscreteParam("max_depth", values = c(1, 3, 9))
)
ps
ctrl <- makeTuneControlGrid()
cv5f <- makeResampleDesc("CV", iters = 5)
results <- tuneParams(
lrn,
task = task,
resampling = cv5f,
par.set = ps,
control = ctrl
)
lrn <- makeLearner(
"regr.xgboost",
par.vals = list(
nrounds = 2,
print.every.n = 200,
#early.stop.round = 5,
#maximize = FALSE,
subsample = 0.5
)
)
ps <- makeParamSet(
makeDiscreteParam("eta", values = 10^(-4:0)),
makeDiscreteParam("max_depth", values = c(1, 3, 9))
)
ctrl <- makeTuneControlGrid()
cv5f <- makeResampleDesc("CV", iters = 5)
results <- tuneParams(
lrn,
task = task,
resampling = cv5f,
par.set = ps,
control = ctrl
)
opt <- as.data.table(results$opt.grid)
opt
results$opt.grid
results$opt.path
opt <- as.data.table(results$opt.path)
opt
g <- ggplot(opt, aes(x = eta, y = max_depth, fill = mse.test.mean))
g + geom_tile() + geom_text(color = "white")
g <- ggplot(opt, aes(x = max_depth, y = mse.test.mean, group = eta, colour = eta))
g + geom_line()
g <- ggplot(opt, aes(
x = max_depth,
y = mse.test.mean,
group = reorder(eta, as.numeric(eta)),
colour = reorder(eta, as.numeric(eta))
))
g + geom_line()
opt[, as.numeric(eta)]
opt[, as.numeric(as.character(eta))]
g <- ggplot(opt, aes(
x = max_depth,
y = mse.test.mean,
group = reorder(eta, as.numeric(as.character(eta))),
colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line()
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
?xgboost
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
lrn <- makeLearner(
"regr.xgboost",
par.vals = list(
nrounds = 2,
print.every.n = 200,
maximize = T,
early.stop.round = 10,
subsample = 0.5
)
)
ps <- makeParamSet(
makeDiscreteParam("eta", values = 10^(-4:0)),
makeDiscreteParam("max_depth", values = c(1, 3, 9))
)
ctrl <- makeTuneControlGrid()
cv5f <- makeResampleDesc("CV", iters = 5)
results <- tuneParams(
lrn,
task = task,
resampling = cv5f,
par.set = ps,
control = ctrl
)
lrn$par.vals
lrn$par.set
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
opt
?tuneParams
ps
?makeParamSet
task <- makeRegrTask(
data = d[, c(demographics, dispositions, maths_literacy[1]), with = F],
target = paste0("PV", 1, "MATH")
)
lrn <- makeLearner(
"regr.xgboost",
par.vals = list(
nrounds = 2000,
print.every.n = 200,
#maximize = FALSE,
#early.stop.round = 10,
subsample = 0.5
)
)
ps <- makeParamSet(
makeDiscreteParam("eta", values = 10^(-3:-1)),
makeDiscreteParam("max_depth", values = c(1, 10))
)
ctrl <- makeTuneControlGrid()
cv5f <- makeResampleDesc("CV", iters = 5)
results <- tuneParams(
lrn,
task = task,
resampling = cv5f,
par.set = ps,
control = ctrl
)
opt <- as.data.table(results$opt.path)
g <- ggplot(opt, aes(
x = max_depth,
y = mse.test.mean,
group = reorder(eta, as.numeric(as.character(eta))),
colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line()
opt
g <- ggplot(opt, aes(
colour = max_depth,
y = mse.test.mean,
x = reorder(eta, as.numeric(as.character(eta))),
#colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line()
g <- ggplot(opt, aes(
colour = max_depth,
y = mse.test.mean,
x = as.numeric(as.character(eta)),
#colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line()
g + geom_line() + coord_cartesian(ylim = 3000)
g + geom_line() + coord_cartesian(ylim = c(0,3000))
g + geom_line()
g + geom_line() + coord_cartesian(ylim = c(0, 5000))
d[, c(demographics, dispositions, maths_literacy[1]), with = F]
?tuneParams
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/2_tuning_and_cv.R', echo=TRUE)
?xgb.importance
opt
g <- ggplot(opt, aes(
colour = max_depth,
y = mae.test.mean,
x = as.numeric(as.character(eta)),
#colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line() #+ coord_cartesian(ylim = c(0, 5000))
g <- ggplot(opt, aes(
x = max_depth,
y = mae.test.mean,
group = as.numeric(as.character(eta)),
colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line()
g <- ggplot(opt, aes(
x = reorder(max_depth, c("1", "4", "16")),
y = mae.test.mean,
group = as.numeric(as.character(eta)),
colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line() #+ coord_cartesian(ylim = c(0, 5000))
## Choose
g <- ggplot(opt, aes(
x = reorder(max_depth, as.numeric(as.character(max_depth))),
y = mae.test.mean,
group = as.numeric(as.character(eta)),
colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line() #+ coord_cartesian(ylim = c(0, 5000))
g <- ggplot(opt, aes(
x = reorder(max_depth, as.numeric(as.character(max_depth))),
y = mae.test.mean,
group = as.numeric(as.character(eta)),
colour = reorder(eta, as.numeric(as.character(eta)))
))
g + geom_line() + geom_point()
sample(nrow(d), 400)
test_set <- sample(nrow(d), 400)
train_set <- 1:nrow(d)[-test_set]
train_set
test_set <- sort(sample(nrow(d), 400))
set.seed(20160522)
test_set <- sort(sample(nrow(d), 400))
train_set <- 1:nrow(d)[-test_set]
test_set
train_set
test_set
(1:nrow(d))[-test_set]
set.seed(20160522)
test_set <- sort(sample(nrow(d), 400))
train_set <- seq(1,nrow(d))[-test_set]
test_set
source('C:/Users/Jason/Projects/pisa-dispositions/Scripts/3_train_xgboost.R', echo=TRUE)
task <- makeRegrTask(
data = d[, c(demographics, dispositions, maths_literacy[1]), with = F],
target = paste0("PV", 1, "MATH")
)
for (col in c("GENDER", "STATE", "GEOLOC", "INDIG"))
set(d, j=col, value=as.factor(d[[col]]))
task <- makeRegrTask(
data = d[, c(demographics, dispositions, maths_literacy[1]), with = F],
target = paste0("PV", 1, "MATH")
)
install.packages("mlr")
devtools::install_github("mlr-org/mlr")
